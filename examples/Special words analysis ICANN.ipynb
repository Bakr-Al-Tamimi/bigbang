{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bigbang.archive import Archive\n",
    "import bigbang.parse as parse\n",
    "import bigbang.graph as graph\n",
    "import bigbang.mailman as mailman\n",
    "import bigbang.process as process\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import pytz\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = [\"http://lists.ncuc.org/pipermail/ncuc-discuss/\",\n",
    "        \"https://mm.icann.org/pipermail/cc-humanrights/\"]#,\n",
    "        #\"http://mail.scipy.org/pipermail/scipy-dev/\",\n",
    "        #\"http://mail.scipy.org/pipermail/scipy-user/\",\n",
    "        #\"http://mail.scipy.org/pipermail/numpy-discussion/\"]\n",
    "\n",
    "\n",
    "archives= [Archive(url,archive_dir=\"../archives\") for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act = archives[0].get_activity()\n",
    "act1 = archives[1].get_activity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gogol/Data/Anaconda2/envs/bigbang/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: order is deprecated, use sort_values(...)\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12.5, 7.5))\n",
    "\n",
    "#act.idxmax().order().T.plot()\n",
    "(act > 0).idxmax().order().plot()\n",
    "\n",
    "fig.axes[0].yaxis_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gogol/Data/Anaconda2/envs/bigbang/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: order is deprecated, use sort_values(...)\n",
      "  if __name__ == '__main__':\n",
      "/home/gogol/Data/Anaconda2/envs/bigbang/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: order is deprecated, use sort_values(...)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "timeorder = (act > 0).idxmax().order()\n",
    "timeorder1 = (act1 > 0).idxmax().order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Date</th>\n",
       "      <th>In-Reply-To</th>\n",
       "      <th>References</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Message-ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93kUAW4A@mail.gmail.com&gt;</th>\n",
       "      <td>rafik.dammak at gmail.com (Rafik Dammak)</td>\n",
       "      <td>[cc-humanrights] test</td>\n",
       "      <td>2014-12-02 01:06:24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test message for the the list\\n-------------- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;547D1589.8010402@apc.org&gt;</th>\n",
       "      <td>joy at apc.org (joy)</td>\n",
       "      <td>[cc-humanrights] ICANN and human rights follow...</td>\n",
       "      <td>2014-12-02 01:27:37</td>\n",
       "      <td>&lt;CAH5sTh=7ZWcKWi9xi1ZE4Za4X_T1ZtzPuyzH80YjLpgP...</td>\n",
       "      <td>&lt;6A0E017DCDD67B4F9566E1578A420C3F61808452@V-Li...</td>\n",
       "      <td>An HTML attachment was scrubbed...\\nURL: &lt;http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        From  \\\n",
       "Message-ID                                                                                     \n",
       "<CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93k...  rafik.dammak at gmail.com (Rafik Dammak)   \n",
       "<547D1589.8010402@apc.org>                                              joy at apc.org (joy)   \n",
       "\n",
       "                                                                                              Subject  \\\n",
       "Message-ID                                                                                              \n",
       "<CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93k...                              [cc-humanrights] test   \n",
       "<547D1589.8010402@apc.org>                          [cc-humanrights] ICANN and human rights follow...   \n",
       "\n",
       "                                                                  Date  \\\n",
       "Message-ID                                                               \n",
       "<CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93k... 2014-12-02 01:06:24   \n",
       "<547D1589.8010402@apc.org>                         2014-12-02 01:27:37   \n",
       "\n",
       "                                                                                          In-Reply-To  \\\n",
       "Message-ID                                                                                              \n",
       "<CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93k...                                               None   \n",
       "<547D1589.8010402@apc.org>                          <CAH5sTh=7ZWcKWi9xi1ZE4Za4X_T1ZtzPuyzH80YjLpgP...   \n",
       "\n",
       "                                                                                           References  \\\n",
       "Message-ID                                                                                              \n",
       "<CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93k...                                               None   \n",
       "<547D1589.8010402@apc.org>                          <6A0E017DCDD67B4F9566E1578A420C3F61808452@V-Li...   \n",
       "\n",
       "                                                                                                 Body  \n",
       "Message-ID                                                                                             \n",
       "<CAH5sThnNsQ5o155O7_NoGLgAW5RTv+r7EncNN1i4Ym93k...  test message for the the list\\n-------------- ...  \n",
       "<547D1589.8010402@apc.org>                          An HTML attachment was scrubbed...\\nURL: <http...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archives[1].data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear fellow members:\n",
      "\n",
      "\n",
      "As you may know, and according to the following Resolution\n",
      "\n",
      "http://ncdnhc.icann-ncc.org/docs/resolution/resolution1.html\n",
      "\n",
      "The members of the NCDNHC has time until Friday 17 to post their\n",
      "Resolution Proposals.\n",
      "\n",
      "The schedule would be the following:\n",
      ">From now to Friday 17:  Posting of Resolution Proposals by members\n",
      "Friday 18 - Wednesday 5: Discussion on Resolution Proposals\n",
      "Friday 7:  NCDNHC meeting in Montevideo\n",
      "\n",
      "Please, take an action and send your Resolution Proposals!\n",
      "\n",
      "Best Regards\n",
      "Vany\n",
      "\n",
      "--\n",
      "Nilda Vany Martinez Grajales\n",
      "Information Technology Specialist\n",
      "Sustainable Development Networking Programme/Panama\n",
      "e-mail: vany at sdnp.org.pa\n",
      "http://www.sdnp.org.pa\n",
      "Hi to all:\n",
      "\n",
      "FYI\n",
      "\n",
      "Best Regards\n",
      "Vany\n",
      "\n",
      "-------- Original Message --------\n",
      "Subject: ccTLD meeting on 7th Sep (ccSO Formation)\n",
      "Date: Sat, 11 Aug 2001 12:03:52 +0900\n",
      "From: \"Byung-Kyu Kim\" <bkkim at wwtld.org>\n",
      "To: <amsiat at gh10.sdnpben.org.bj>, <vany at sdnp.org.pa>,\n",
      "<mueller at syracuse.edu>,<yjpark at myEpark.com>, <vandrome at renater.fr>\n",
      "\n",
      "Dear Non-Commercial Domain Name Holders Constituency:\n",
      "\n",
      "The ccTLD Constituency is panning to announce the Resolution for\n",
      "the ccSO Formation in the Montevideo ccTLD meeting on 7th Sep.\n",
      "\n",
      "We heartily invite you in order to hear your opinions before we get the\n",
      "final announcement of the ccTLD Constituency. It will start on 7th Sep\n",
      "2:00 pm.\n",
      "\n",
      "If your schedules are available on that time windows, could you\n",
      "participate\n",
      "in the ccTLD meeting and give us your comments ?\n",
      "\n",
      "Thank you very much.\n",
      "\n",
      "Sincerely yours,\n",
      "\n",
      "ByungKyu Kim\n",
      "****************************************************\n",
      "ByungKyu Kim, Ph.D.\n",
      "Executive Director, ccTLD Secretariat\n",
      "ccTLD Constituency of the DNSO, ICANN\n",
      "TEL: +82-2-2186-4533, FAX: +82-2-2186-4599\n",
      "Email: bkkim at wwtld.org, URL: http://www.wwtld.org\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "for row in archives[0].data[:2].iterrows():\n",
    "    print row[1][\"Body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arx = archives[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_participation = {}\n",
    "for row in archives[0].data.iterrows():\n",
    "    if row[1][\"From\"] not in first_participation:\n",
    "        first_participation[row[1][\"From\"]] = row[1][\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_participation1 = {}\n",
    "for row in archives[1].data.iterrows():\n",
    "    if row[1][\"From\"] not in first_participation1:\n",
    "        first_participation1[row[1][\"From\"]] = row[1][\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-783937edc545>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwordcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marchives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Body\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "#First list\n",
    "wordcount={}\n",
    "for row in archives[0].data.iterrows():\n",
    "    try:\n",
    "        w = row[1][\"Body\"].replace(\"'\", \"\")\n",
    "        k = re.sub(r'[^\\w]', ' ', w)\n",
    "        t = nltk.tokenize.word_tokenize(k)\n",
    "        for g in t:\n",
    "            try:\n",
    "                word = st.stem(g)\n",
    "            except:\n",
    "                print g\n",
    "                pass\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            if word not in wordcount:\n",
    "                wordcount[word] = [1]\n",
    "                wordcount[word].append(row[0])\n",
    "                wordcount[word].append(row[1][\"Date\"])\n",
    "                wordcount[word].append(row[1][\"From\"])\n",
    "                wordcount[word].append(row[1][\"In-Reply-To\"])\n",
    "            else:\n",
    "                wordcount[word][0] += 1\n",
    "    except:\n",
    "        if row[1][\"Body\"] is None: print '[Warning] Detected empty mail body\n",
    "wd = wordcount #In case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Second List\n",
    "wordcount1={}\n",
    "for row in archives[1].data.iterrows():\n",
    "    try:\n",
    "        w = row[1][\"Body\"].replace(\"'\", \"\")\n",
    "        k = re.sub(r'[^\\w]', ' ', w)\n",
    "        t = nltk.tokenize.word_tokenize(k)\n",
    "        for g in t:\n",
    "            try:\n",
    "                word = st.stem(g)\n",
    "            except:\n",
    "                print g\n",
    "                pass\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            if word not in wordcount1:\n",
    "                wordcount1[word] = [1]\n",
    "                wordcount1[word].append(row[0])\n",
    "                wordcount1[word].append(row[1][\"Date\"])\n",
    "                wordcount1[word].append(row[1][\"From\"])\n",
    "                wordcount1[word].append(row[1][\"In-Reply-To\"])\n",
    "            else:\n",
    "                wordcount1[word][0] += 1"
    "        except:\n",
    "            if row[1][\"Body\"] is None: print '[Warning] Detected empty mail body\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_df = pd.DataFrame(wordcount.items(),columns=[\"Word\",\"Others\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.concat(pd.Series(wordcount.keys()),pd.DataFrame(wordcount.values(),columns=[\"A\",\"B\",\"C\",\"D\",\"E\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Wordcount information dataframe, with rows as words.\n",
    "asd = pd.DataFrame(wordcount)\n",
    "new_dataframe = asd.transpose()\n",
    "new_dataframe.columns = [\"Wordcount\", \"Message-ID\", \"Date\",\"From\",\"In-Reply-To\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Wordcount information dataframe, with rows as words.\n",
    "asd1 = pd.DataFrame(wordcount1)\n",
    "new_dataframe1 = asd1.transpose()\n",
    "new_dataframe1.columns = [\"Wordcount\", \"Message-ID\", \"Date\",\"From\",\"In-Reply-To\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(wordcount) #Number of unique words in mailing list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(wordcount1) #Number of unique words in mailing list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Number of same unique words in two mailing lists\n",
    "samewordcount=0\n",
    "for word in wordcount:\n",
    "    if word in wordcount1:\n",
    "        samewordcount += 1\n",
    "samewordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Total number of same words that are introduced by same people.\n",
    "samecount = 0\n",
    "for word in wordcount:\n",
    "    if word in wordcount1:\n",
    "        if wordcount[word][3] == wordcount1[word][3]:\n",
    "            samecount += 1\n",
    "samecount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Among 100-500 appearance words, the number of common words between two mailing-list.\n",
    "samewordcount = 0\n",
    "for word in wordcount:\n",
    "    if wordcount[word][0] >= 100 and wordcount[word][0] <= 500:\n",
    "        if word in wordcount1:\n",
    "            if wordcount1[word][0] >= 100 and wordcount1[word][0] <= 500:\n",
    "                samewordcount += 1\n",
    "samewordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Among 100-500 appearance words, the number of common words between two mailing-list that are first\n",
    "#introduced by same people\n",
    "same_person_count = 0\n",
    "for word in wordcount:\n",
    "    if wordcount[word][0] >= 100 and wordcount[word][0] <= 500:\n",
    "        if word in wordcount1:\n",
    "            if wordcount1[word][0] >= 100 and wordcount1[word][0] <= 500:\n",
    "                if wordcount[word][3] == wordcount1[word][3]:\n",
    "                    #print word\n",
    "                    same_person_count += 1\n",
    "samecount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#common word list(introduced by different people in different lists)\n",
    "commonwords = {}\n",
    "for word in wordcount:\n",
    "    if wordcount[word][0] >= 100 and wordcount[word][0] <= 500:\n",
    "        if word in wordcount1:\n",
    "            if wordcount1[word][0] >= 100 and wordcount1[word][0] <= 500:\n",
    "                if wordcount[word][3] != wordcount1[word][3]:\n",
    "                    commonwords[word] = [wordcount[word][0],wordcount[word][3],wordcount[word][2],\\\n",
    "                                         wordcount1[word][0],wordcount1[word][3],wordcount1[word][2]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(commonwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataframe of information of those words introduced by different people\n",
    "df1 = pd.DataFrame(commonwords)\n",
    "commonword_differentauthor_dataframe = df1.transpose()\n",
    "commonword_differentauthor_dataframe.columns = [\"Wordcount1\", \"From1\", \"Date1\",\"Wordcount2\", \"From2\", \"Date2\"]\n",
    "commonword_differentauthor_dataframe[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commonword_differentauthor_dataframe['Date1'][0] < commonword_differentauthor_dataframe['Date1'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(commonwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The list of words that have potential of idea flows. Definition: A is introduced by p in list1 first, then q saw it and then \n",
    "# introduced the word A to list 2, vice versa. We defined q saw as q said sth in list1 before p poped out the word. \n",
    "# Total list of such word A. \n",
    "time_influence = 0\n",
    "influnce_list = {}\n",
    "for word in commonwords:\n",
    "    if commonwords[word][2] > commonwords[word][5]: #Author2 comes first\n",
    "        if commonwords[word][1] in first_participation1: #Check if author1 in list2\n",
    "            if first_participation1[commonwords[word][1]] < commonwords[word][5]: #Check if author1\\\n",
    "                #in list2 and exists before the word first introduced in list2\n",
    "                influnce_list[word] = commonwords[word]\n",
    "                time_influence += 1\n",
    "    else: #Author1 comes first\n",
    "        if commonwords[word][4] in first_participation:\n",
    "            if first_participation[commonwords[word][4]] < commonwords[word][2]:\n",
    "                influnce_list[word] = commonwords[word]\n",
    "                time_influence += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(influnce_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(influnce_list)\n",
    "influnce_list_dataframe = df2.transpose()\n",
    "influnce_list_dataframe.columns = [\"Wordcount1\", \"From1\", \"Date1\",\"Wordcount2\", \"From2\", \"Date2\"]\n",
    "influnce_list_dataframe[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence_words = influnce_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reduce the words that only contain numbers (lack of information)\n",
    "reduced_influence_words = [] \n",
    "for word in influence_words:\n",
    "    if word.isdigit() == False:\n",
    "        reduced_influence_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(reduced_influence_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_influence_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store the list\n",
    "import csv\n",
    "with open('test123.csv', 'w') as fp:\n",
    "    a = csv.writer(fp)\n",
    "    data = [reduced_influence_words]\n",
    "    a.writerows(data)\n",
    "\n",
    "#reduced_influence_words.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of main contents of this notebook, below are some analysis of unique word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influnce_list_dataframe.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key,value in wd.items():\n",
    "    if value <= 100 or value >= 500:\n",
    "        del wd[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc_array = np.array(wd.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc_array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List1's unique words and their count, power law distribution\n",
    "%matplotlib inline\n",
    "plt.plot(wcsort_array[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = nltk.tokenize.word_tokenize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in t:\n",
    "    a.append(st.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
